{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e49678a4-3895-486c-a878-18b53d2f9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "m1 = torch.device(\"mps\")\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b1a67-473d-4496-bf2e-fa96a47c2e57",
   "metadata": {},
   "source": [
    "# Transformer Model\n",
    "https://arxiv.org/pdf/1706.03762.pdf\n",
    "\n",
    "Super helpful walkthrough: http://nlp.seas.harvard.edu/annotated-transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68c93796-5f49-43c7-a272-99bf23dc04e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chars in dictionary\n",
    "vocab = 30\n",
    "\n",
    "# d_model is the same as embedding same for simplicity.\n",
    "# embs = 12\n",
    "d_model = 12\n",
    "\n",
    "# number of chars to see in one window\n",
    "window = 16\n",
    "\n",
    "# This will increase one day\n",
    "batch_size = 5\n",
    "\n",
    "heads = 3\n",
    "\n",
    "blocks = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc54ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = torch.randint(vocab, (batch_size, window))\n",
    "prompts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06144259-ded5-46fe-ae47-d4262846e92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16, 12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab, d_model)\n",
    "        self.sqrt_d_model = math.sqrt(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x) * self.sqrt_d_model\n",
    "\n",
    "emb_prompts = Embeddings(d_model, vocab)(prompts)\n",
    "emb_prompts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7723746e-387a-422a-a209-d1f5f93b922d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16, 12])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    ## Thank you! https://jalammar.github.io/illustrated-transformer/\n",
    "    # for evens:  sin(pos/10000**(2i/embs))\n",
    "    # for odds:   cos(pos/10000**(2i/embs))\n",
    "    def __init__(self, d_model, window):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pos_idxs = torch.arange(0, window).view(-1, 1)\n",
    "        emb_idxs = torch.arange(0, d_model).view(1, -1)\n",
    "        \n",
    "        \n",
    "        angles = pos_idxs / (10000**(2*emb_idxs / d_model))\n",
    "\n",
    "        self.pos_enc_tmp = torch.zeros(window, d_model)\n",
    "        self.pos_enc_tmp[:, 0::2] += torch.sin(angles[:, 0::2])\n",
    "        self.pos_enc_tmp[:, 1::2] += torch.cos(angles[:, 1::2])\n",
    "\n",
    "        self.register_buffer(\"pos_enc\", self.pos_enc_tmp)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.shape[0]\n",
    "        # For some reason I thought you concatenated these, but you add instead. Interesting.\n",
    "        # return torch.cat((x, self.pos_enc.unsqueeze(0).repeat(N, 1, 1)), dim=2)\n",
    "        return x + self.pos_enc\n",
    "\n",
    "# pos_enc = PositionalEncoding(embs, window)\n",
    "\n",
    "# # Plot the positional embeddings\n",
    "# plt.pcolormesh(pos_enc.pos_enc, cmap='viridis')\n",
    "# plt.xlabel('Embedding Dimensions')\n",
    "# plt.xlim((0, embs))\n",
    "# plt.ylim((window,0))\n",
    "# plt.ylabel('Char Position')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "enc_prompt = PositionalEncoding(d_model, window)(emb_prompts)\n",
    "enc_prompt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1763b3b2-8f6a-4412-8802-3f529b847bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def attention(q, k, v):\n",
    "    d_k = q.size(-1)\n",
    "    scores = q @ k.transpose(-2, -1) / math.sqrt(d_k)\n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    return torch.matmul(p_attn, v), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed108a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 16, 12])\n"
     ]
    }
   ],
   "source": [
    "class GptAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    For this attention module k = v = q are all the same.\n",
    "    It's for encoder only transfomers.\n",
    "    \"\"\"\n",
    "    def __init__(self, heads, d_model):\n",
    "        super(GptAttention, self).__init__()\n",
    "        assert d_model % heads == 0\n",
    "\n",
    "        self.heads = heads\n",
    "\n",
    "        ## I've seen combining these into a single linear layer\n",
    "        # This seems weird to me because k,v,q will cross and change eachother\n",
    "        #\n",
    "        self.W = clones(nn.Linear(d_model, 3*d_model), heads)\n",
    "        # self.Wq = clones(nn.Linear(d_model, d_model), heads)\n",
    "        # self.Wv = clones(nn.Linear(d_model, d_model), heads)\n",
    "        # self.Wk = clones(nn.Linear(d_model, d_model), heads)\n",
    "\n",
    "        self.linear = nn.Linear(d_model * heads, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, window, embs = x.shape\n",
    "        att_out = []\n",
    "        for i in range(self.heads):\n",
    "            q, v, k = self.W[i](x).split(d_model, dim=2)\n",
    "            # q = self.Wq[i](x)\n",
    "            # v = self.Wv[i](x)\n",
    "            # k = self.Wk[i](x)\n",
    "            att, _ = attention(q, k, v)\n",
    "            att_out.append(att)\n",
    "        out = torch.cat(att_out, dim=2)\n",
    "        \n",
    "        return self.linear(out)\n",
    "\n",
    "gpt_attn = GptAttention(6, d_model)\n",
    "out = gpt_attn(enc_prompt)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ba13ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.l1 = nn.Linear(d_model, 2*d_model)\n",
    "        self.l2 = nn.Linear(2*d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        return self.l2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0cb2b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(Norm, self).__init__()\n",
    "        self.a = nn.Parameter(torch.ones(features))\n",
    "        self.b = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a * (x - mean) / (std + self.eps) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c1521db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 16, 12])\n"
     ]
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, d_model, heads):\n",
    "        super(Block, self).__init__()\n",
    "        self.attn = GptAttention(heads, d_model)\n",
    "        self.norm1 = Norm(d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.norm2 = Norm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn = self.attn(x)\n",
    "        x = self.norm1(x + attn)\n",
    "        ff = self.ff(x)\n",
    "        x = self.norm2(x + ff)\n",
    "        return x\n",
    "\n",
    "b = Block(d_model, 3)\n",
    "out = b(emb_prompts)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a13c24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 16, 30])\n",
      "torch.Size([5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [5, 30], got [5]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [67], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mprint\u001b[39m(logits\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     30\u001b[0m \u001b[39mprint\u001b[39m(Y\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 31\u001b[0m dev_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mcross_entropy(logits, Y)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [5, 30], got [5]"
     ]
    }
   ],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, d_model, heads, blocks):\n",
    "        super(GPT, self).__init__()\n",
    "        self.vocab_emb = Embeddings(d_model, vocab)\n",
    "        self.pos_emb = PositionalEncoding(d_model, window)\n",
    "        self.blocks = clones(Block(d_model, heads), blocks)\n",
    "        self.l_out = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vocab_emb(x)\n",
    "        x = self.pos_emb(x)\n",
    "        for b in self.blocks:\n",
    "            x = b(x)\n",
    "        x = self.l_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def sample_char(self, x):\n",
    "        logits = self(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        return torch.multinomial(probs, num_samples=1).item()\n",
    "        \n",
    "\n",
    "gpt = GPT(d_model, heads, blocks)\n",
    "\n",
    "X, Y = torch.squeeze(Xtr[:5]), torch.squeeze(Ytr[:5])\n",
    "\n",
    "logits = gpt(X)\n",
    "print(logits.shape)\n",
    "print(Y.shape)\n",
    "dev_loss = F.cross_entropy(logits, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e8547",
   "metadata": {},
   "source": [
    "# Now let's make it run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c982ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = open('compiled_names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d10dbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions to convert chars to int and inverse\n",
    "\n",
    "chars = sorted(list(set(''.join(names))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "\n",
    "# . is both \"before start\" in X, and \"im done\" for Y\n",
    "stoi['.'] = 0\n",
    "itos = {s:i for i,s in stoi.items()}\n",
    "\n",
    "num_char = len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa59ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, device):\n",
    "    x, y = [], []\n",
    "\n",
    "    for word in words:\n",
    "        for i, c in enumerate(word + '.'):\n",
    "            mini_x = []\n",
    "            for w in reversed(range(1, window+1)):\n",
    "                if i - w >= 0:\n",
    "                    mini_x.append(stoi[word[i-w]])\n",
    "                else:\n",
    "                    mini_x.append(stoi['.'])\n",
    "\n",
    "            x.append(mini_x)\n",
    "            y.append(stoi[c])\n",
    "            \n",
    "    return torch.tensor(x, device=device), torch.tensor(y, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daf26a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(names)\n",
    "n1 = int(0.8*len(names))\n",
    "n2 = int(0.9*len(names))\n",
    "\n",
    "Xtr, Ytr = build_dataset(names[:n1], device=cpu)\n",
    "Xdev, Ydev = build_dataset(names[n1:n2], device=cpu)\n",
    "Xte, Yte = build_dataset(names[n2:], device=cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933fc08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50): \n",
    "    print(\"{} --> {}\".format([itos[c.item()] for c in Xtr[i]], itos[Ytr[i].item()]))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc2ae47d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [64, 30], got [64]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [63], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m# forward\u001b[39;00m\n\u001b[1;32m     22\u001b[0m logits \u001b[39m=\u001b[39m network(X)\n\u001b[0;32m---> 23\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mcross_entropy(logits, Y)\n\u001b[1;32m     25\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     26\u001b[0m     opt\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [64, 30], got [64]"
     ]
    }
   ],
   "source": [
    "network = GPT(d_model, heads, blocks)\n",
    "network.to(m1)\n",
    "network.train(mode=True)\n",
    "\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "steps = []\n",
    "losses = []\n",
    "dev_steps = []\n",
    "dev_losses = []\n",
    "batch_size = 64\n",
    "max_steps = 200000\n",
    "rec_freq = 2000\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for i in range(max_steps+1):\n",
    "    # sample from training set\n",
    "    sample_idx = torch.randint(len(Ytr), size=(batch_size,1))\n",
    "    X, Y = torch.squeeze(Xtr[sample_idx].to(m1)), torch.squeeze(Ytr[sample_idx].to(m1))\n",
    "    \n",
    "    # forward\n",
    "    logits = network(X)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    ## Record data\n",
    "    steps.append(i)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if i % rec_freq == 0: # print every once in a while\n",
    "        dev_loss = 0\n",
    "        with torch.no_grad():\n",
    "            dev_idx = torch.randint(len(Ydev), size=(batch_size,1))\n",
    "            X_check, Y_check = torch.squeeze(Xdev[dev_idx].to(m1)), torch.squeeze(Ydev[dev_idx].to(m1))\n",
    "\n",
    "            dev_loss = F.cross_entropy(network(X_check), Y_check)\n",
    "            \n",
    "        current_time = time.perf_counter()\n",
    "        dt = current_time - start_time\n",
    "        print(f'{i:7d}/{max_steps:7d}: dt: {dt:.2f} dev_loss: {dev_loss.item():.4f} loss: {loss.item():.4f}')\n",
    "        \n",
    "        dev_losses.append(dev_loss.item())\n",
    "        dev_steps.append(i)\n",
    "\n",
    "\n",
    "current_time = time.perf_counter()\n",
    "dt = current_time - start_time\n",
    "print(\"total training time: {}\".format(dt))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "18e189b7a455dca94c157be0e0713a038d2605132cba86745af50b7dbf438d16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
